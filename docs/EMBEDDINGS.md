## Configura√ß√£o de Embeddings Vetoriais e Busca H√≠brida

Esta documenta√ß√£o explica como ativar e operar o pipeline de embeddings com pgvector para melhorar as sugest√µes de classifica√ß√£o dentro do WhatsApp Clone IA.

### 1. Pr√©-requisitos

- PostgreSQL ‚â• 16 com extens√£o **pgvector** instalada:
  ```sql
  CREATE EXTENSION IF NOT EXISTS vector;
  ```
- Vari√°veis de ambiente configuradas no backend:
  ```ini
  FEATURE_EMBEDDING=true            # habilita gera√ß√£o de embeddings
  OPENAI_API_KEY=sk-...             # ou configure provedor local/ollama
  EMBEDDING_PROVIDER=openai         # openai | local
  OPENAI_MODEL_EMBEDDING=text-embedding-3-small
  CLASSIFICACAO_VECTOR_WEIGHT=0.5   # 0 = apenas keywords, 1 = apenas vetor
  ```

### 2. Ajustes de Rate Limit para Produ√ß√£o

Defina limites mais permissivos (ou utilize Redis compartilhado) no `.env`:

```ini
RATE_LIMIT_WINDOW_MS=60000    # 1 minuto
RATE_LIMIT_MAX_REQUESTS=1000  # por IP dentro da janela
REDIS_URL=redis://user:senha@host:6379/0   # opcional, para ambientes com m√∫ltiplas inst√¢ncias
```

Com `REDIS_URL` presente, o middleware usa `rate-limit-redis` automaticamente como store compartilhado.

### 3. Aplicar migrations e √≠ndices

```bash
psql -d whatsapp_clone -f backend/migrations/003_add_conversa_classificacao.sql
psql -d whatsapp_clone -f backend/migrations/004_add_vector_indexes.sql
```

### 4. Executar setup completo da busca vetorial

```bash
cd backend
npm install
npm run setup:vector-search
```

O script:
1. Valida a presen√ßa do pgvector.
2. Garante a coluna `embedding` em `classificacao_catalogo`.
3. Cria √≠ndices `ivfflat` para `mensagens`, `classificacao_catalogo` e `conversa_contexto`.
4. Roda o backfill de embeddings (cat√°logo, mensagens e base de conhecimento).

## üöÄ Op√ß√µes de Setup

### Setup Completo (recomendado para primeira instala√ß√£o)
```bash
npm run setup:vector-search
```

Este comando:
- ‚úÖ Valida extens√£o pgvector
- ‚úÖ Cria √≠ndices IVFFLAT
- ‚úÖ Executa backfill de embeddings existentes

### Apenas Backfill (para processar novos dados)
```bash
npm run backfill-embeddings
```

Processa apenas registros sem embedding. √ötil para:
- Atualizar dados ap√≥s importa√ß√£o
- Reprocessar ap√≥s mudan√ßa de modelo
- Recuperar de falhas anteriores

### Aliases Dispon√≠veis
```bash
npm run embeddings:setup      # Mesmo que setup:vector-search
npm run embeddings:backfill   # Mesmo que backfill-embeddings
npm run embeddings:diagnose   # Diagn√≥stico completo do sistema
```

### 5. Gera√ß√£o cont√≠nua de embeddings

- Mensagens novas s√£o processadas pelo worker (`npm run worker:embedding`).
- Itens sem embedding em `conhecimento_base` e `classificacao_catalogo` s√£o enfileirados automaticamente pelos crons `EMBEDDING_KB_CRON` e `EMBEDDING_CATALOG_CRON`.
- Para reprocessar hist√≥rico a qualquer momento:
  ```bash
  npm run backfill-embeddings
  ```
- Ajuste `EMBEDDING_BACKFILL_MAX_EMPTY` e `EMBEDDING_BACKFILL_SLEEP_MS` para evitar loops infinitos caso o provedor de embeddings esteja offline. O script aborta ap√≥s atingir o limite de ciclos sem progresso.

### 6. Contextos agregados de conversa

- O scheduler `CONVERSA_CONTEXTO_CRON` agrupa blocos de mensagens em `conversa_contexto`, gera um resumo com t√≥picos principais e, se `FEATURE_EMBEDDING=true`, cria embeddings do resumo.
- Par√¢metros ajust√°veis:
  - `CONTEXT_SUMMARY_WINDOW_SIZE`: m√°ximo de mensagens por janela consolidada.
  - `CONTEXT_SUMMARY_MIN_MESSAGES`: m√≠nimo desejado antes de gerar um novo bloco (exceto o √∫ltimo restante).
  - `CONTEXT_SUMMARY_CONVERSATION_LIMIT`: quantas conversas s√£o processadas por ciclo.
  - `CONTEXT_SUMMARY_MAX_TOKENS`: limite de tokens na chamada do modelo de resumo.
- Cada registro em `conversa_contexto` guarda `metadata.last_message_id`; isso evita janelas duplicadas e garante continuidade entre execu√ß√µes.

### 7. Busca h√≠brida (keywords + vetorial)

- A rota `GET /api/conversas/:id/sugestoes` utiliza:
  - Busca por keywords (compat√≠vel com vers√µes antigas).
  - Similaridade vetorial (quando `FEATURE_EMBEDDING=true` e embeddings dispon√≠veis).
- O peso relativo √© controlado por `CLASSIFICACAO_VECTOR_WEIGHT`.
  - `0.0` ‚Üí apenas keywords.
  - `0.5` ‚Üí combina√ß√£o equilibrada (padr√£o recomendado).
  - `1.0` ‚Üí apenas vetor.

### 8. Monitoramento e troubleshooting

- Logs (`logger.debug`) registram o tempo de cada busca (`keywords` e `vector`).
- Se a busca vetorial falhar ou n√£o houver embeddings, o servi√ßo faz fallback autom√°tico para keywords.
- Use `SELECT COUNT(*) FROM classificacao_catalogo WHERE embedding IS NULL;` para checar itens pendentes.
- Caso a API de embeddings fique indispon√≠vel, o sistema continua operacional (apenas com keywords).

### 9. Pr√≥ximos passos sugeridos

- Habilitar cache de embeddings de consultas frequentes (Redis).
- Ajustar `WITH (lists = X)` dos √≠ndices `ivfflat` conforme o volume de dados.
- Monitorar custo de gera√ß√£o de embeddings para dimensionar lotes (`EMBEDDING_BACKFILL_MAX_PER_RUN`).

## üîß Troubleshooting

### ‚ùå Erro: "Loop infinito no backfill"

**Sintoma:** Script fica rodando sem progresso, eventualmente aborta.

**Causas poss√≠veis:**
- Provider retornando 503 (servi√ßo temporariamente indispon√≠vel)
- Rate limit sendo atingido repetidamente
- Credenciais inv√°lidas causando falhas silenciosas

**Solu√ß√£o:**

1. **Execute diagn√≥stico primeiro:**
```bash
npm run embeddings:diagnose
```

2. **Se for rate limit do provider:**
```bash
# Reduza o batch size no .env
EMBEDDING_BACKFILL_BATCH_SIZE=50

# Aumente o n√∫mero de retries
EMBEDDING_BACKFILL_MAX_RETRIES=5
# Evite reprocessar mensagens vazias
EMBEDDING_MARK_EMPTY_AS_SKIPPED=true
```

3. **Se for 503 tempor√°rio:**
   - Aguarde 5-10 minutos
   - Execute novamente (o script retoma de onde parou)

---

### ‚ùå Erro: "Credenciais inv√°lidas" ou 401/403

**Sintoma:** Backfill falha imediatamente com erro de autentica√ß√£o.

**Solu√ß√£o:**

1. **Verifique a API key:**
```bash
# No .env, confirme que existe:
OPENAI_API_KEY=sk-proj-...
```

2. **Teste manualmente:**
```bash
npm run embeddings:diagnose
```

3. **Confirme permiss√µes:**
   - A key precisa ter acesso ao endpoint de embeddings
   - Verifique no painel do provider se a key est√° ativa

---

### ‚ö†Ô∏è Performance lenta (> 1s por embedding)

**Causas:**
- √çndices vetoriais ausentes
- Batch size muito alto
- Lat√™ncia de rede com provider

**Solu√ß√£o:**

1. **Verifique √≠ndices:**
```bash
npm run embeddings:diagnose
# Se faltar √≠ndices, recrie:
npm run setup:vector-search
```

2. **Ajuste batch size:**
```bash
# No .env
EMBEDDING_BACKFILL_BATCH_SIZE=50  # Valor menor
```

3. **Considere provider alternativo:**
   - Azure OpenAI (geralmente mais r√°pido para BR)
   - Cohere (suporta batch nativo)

---

### üîÑ Como reverter mudan√ßas

Se precisar desativar embeddings temporariamente:
```bash
# 1. Desativar feature no .env
FEATURE_EMBEDDING=false

# 2. (Opcional) Remover √≠ndices para liberar espa√ßo
psql -d seu_banco <<SQL
DROP INDEX IF EXISTS idx_mensagens_embedding;
DROP INDEX IF EXISTS idx_classificacao_catalogo_embedding;
DROP INDEX IF EXISTS idx_conversa_contexto_embedding;
SQL

# 3. (Opcional) Limpar embeddings para liberar espa√ßo
psql -d seu_banco <<SQL
UPDATE mensagens SET embedding = NULL;
UPDATE classificacao_catalogo SET embedding = NULL;
UPDATE conversa_contexto SET embedding = NULL;
SQL
```

---

### üìû Suporte

Se os problemas persistirem:

1. Execute e compartilhe o diagn√≥stico:
```bash
npm run embeddings:diagnose > diagnostico.txt
```

2. Verifique logs do backend:
```bash
tail -f backend/logs/error.log | grep -i embedding
```

3. Teste busca vetorial manualmente:
```sql
-- No psql, verifique se vetores est√£o sendo usados:
EXPLAIN ANALYZE
SELECT id, 1 - (embedding <=> '[0.1, 0.2, ...]'::vector) AS score
FROM mensagens
WHERE embedding IS NOT NULL
ORDER BY embedding <=> '[0.1, 0.2, ...]'::vector
LIMIT 5;
```
